{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a184eb",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bf7d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a442628",
   "metadata": {},
   "source": [
    "- This code defines a pool of 8 grocery items and generates 10 fake shopping transactions. Each transaction contains 2 to 5 randomly selected items. The results are stored in a list called transactions and printed out with clear labels like \"Transaction 1\", \"Transaction 2\", etc. A random seed is set to make the output reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eafe1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction 1: ['Apples', 'Bananas']\n",
      "Transaction 2: ['Bananas', 'Milk', 'Bread']\n",
      "Transaction 3: ['Milk', 'Bananas', 'Apples', 'Eggs', 'Butter']\n",
      "Transaction 4: ['Eggs', 'Bread', 'Butter', 'Bananas', 'Apples']\n",
      "Transaction 5: ['Bananas', 'Chicken']\n",
      "Transaction 6: ['Apples', 'Butter', 'Cheese', 'Chicken']\n",
      "Transaction 7: ['Cheese', 'Chicken', 'Bread']\n",
      "Transaction 8: ['Butter', 'Bananas', 'Apples', 'Chicken', 'Cheese']\n",
      "Transaction 9: ['Bananas', 'Butter']\n",
      "Transaction 10: ['Apples', 'Chicken', 'Bananas']\n"
     ]
    }
   ],
   "source": [
    "# Define a pool of items\n",
    "item_pool = ['Milk', 'Eggs', 'Butter', 'Cheese', 'Bananas', 'Bread', 'Apples', 'Chicken']\n",
    "\n",
    "# Generate 10 fake transactions, each with 2–5 random items\n",
    "random.seed(42)  # for reproducibility\n",
    "transactions = []\n",
    "for _ in range(10):\n",
    "    num_items = random.randint(2, 5)\n",
    "    transaction = random.sample(item_pool, num_items)\n",
    "    transactions.append(transaction)\n",
    "\n",
    "# Display transactions\n",
    "for i, t in enumerate(transactions, 1):\n",
    "    print(f\"Transaction {i}: {t}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe36e2",
   "metadata": {},
   "source": [
    "- This code extracts all unique items from the transaction list, encodes each transaction by marking whether each item is present (True) or not (False), and creates a one-hot encoded DataFrame where rows represent transactions and columns represent items.\n",
    "- Encoding the transactions is important because the Apriori algorithm only takes values in binary format (True/False or 1/0), which allows it to compute item frequencies, identify frequent itemsets, and generate meaningful association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9c2c83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract all unique items from the transactions\n",
    "all_items = sorted(set(item for transaction in transactions for item in transaction))\n",
    "\n",
    "# Step 2: Manually one-hot encode\n",
    "Encoded_data = []\n",
    "for transaction in transactions:\n",
    "    Encoded_data.append({item: (item in transaction) for item in all_items})\n",
    "\n",
    "# Step 3: Create a DataFrame\n",
    "df_new = pd.DataFrame(Encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82f79a",
   "metadata": {},
   "source": [
    "- The section of code below applies the Apriori algorithm to the one-hot encoded transaction DataFrame df_new, using a minimum support threshold of 0.3 (meaning an itemset must appear in at least 30% of the transactions to be considered frequent).\n",
    "The use_colnames=True argument ensures that the item names (e.g., 'Apples', 'Bananas') are shown instead of their column indices.\n",
    "The result, stored in frequent_itemsets, is printed and shows all item combinations (itemsets) that meet or exceed the support threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263d811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support                   itemsets\n",
      "0       0.6                   (Apples)\n",
      "1       0.8                  (Bananas)\n",
      "2       0.3                    (Bread)\n",
      "3       0.5                   (Butter)\n",
      "4       0.3                   (Cheese)\n",
      "5       0.5                  (Chicken)\n",
      "6       0.5          (Bananas, Apples)\n",
      "7       0.4           (Apples, Butter)\n",
      "8       0.3          (Apples, Chicken)\n",
      "9       0.4          (Bananas, Butter)\n",
      "10      0.3         (Bananas, Chicken)\n",
      "11      0.3          (Cheese, Chicken)\n",
      "12      0.3  (Bananas, Apples, Butter)\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = apriori(df_new, min_support=0.3, use_colnames=True)\n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0eac63",
   "metadata": {},
   "source": [
    "- Association rules are generated below using confidence as the evaluation metric and a minimum threshold of 0.7, meaning only rules where the consequent appears at least 70% of the time given the antecedent are included. The rules DataFrame contains key metrics such as support, confidence, and lift, which help in understanding the strength and relevance of each rule. The first two rules are then displayed to give insight into the most confident item associations within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f473601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "   antecedents consequents  support  confidence      lift\n",
      "3    (Cheese)   (Chicken)      0.3    1.000000  2.000000\n",
      "0    (Apples)   (Bananas)      0.5    0.833333  1.041667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate rules using confidence >= 0.7\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "# Sort rules by confidence in descending order and select the top 2\n",
    "top_rules = rules.sort_values(by='confidence', ascending=False).head(2)\n",
    "\n",
    "# Display at least 2 rules\n",
    "print(\"\\nAssociation Rules:\\n\", top_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93f35a",
   "metadata": {},
   "source": [
    "## Eplanation of rule one in everyday life:\n",
    "“If someone buys Apples, there is a 83.3% chance they will also buy Bananas. So, a store could place these items closer together or bundle them for promotions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
